# Synexs Orchestrator Deployment Guide

## Overview
The Synexs Core Orchestrator is the central AI-powered coordination system that runs all cells in a 5-phase pipeline with continuous learning capabilities.

## Current Status
- âœ… AI Integration Complete (Shadow Mode)
- âœ… V3 Binary Protocol (78.6% bandwidth reduction)
- âœ… All tests passing (6/6)
- âœ… One successful orchestration cycle completed

---

## Deployment Options

### **Option 1: Systemd Service (Recommended for Production)**

The orchestrator runs as a background systemd service that:
- Starts automatically on system boot
- Restarts automatically if it crashes
- Logs to journalctl and file logs
- Can be controlled with `systemctl` commands

#### Setup Instructions

1. **Create systemd service file:**
```bash
sudo tee /etc/systemd/system/synexs-orchestrator.service > /dev/null << 'EOF'
[Unit]
Description=Synexs Core Orchestrator with AI Integration
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/root/synexs
ExecStart=/root/synexs/synexs_env/bin/python3 /root/synexs/synexs_core_orchestrator.py
Restart=always
RestartSec=10
StandardOutput=append:/root/synexs/synexs_core.log
StandardError=append:/root/synexs/synexs_core.log

# Environment
Environment="PYTHONUNBUFFERED=1"

[Install]
WantedBy=multi-user.target
EOF
```

2. **Enable and start the service:**
```bash
sudo systemctl daemon-reload
sudo systemctl enable synexs-orchestrator
sudo systemctl start synexs-orchestrator
```

3. **Check status:**
```bash
sudo systemctl status synexs-orchestrator
```

4. **View logs:**
```bash
# Real-time logs
sudo journalctl -u synexs-orchestrator -f

# Or view the log file
tail -f /root/synexs/synexs_core.log
```

5. **Control the service:**
```bash
sudo systemctl stop synexs-orchestrator    # Stop
sudo systemctl start synexs-orchestrator   # Start
sudo systemctl restart synexs-orchestrator # Restart
```

---

### **Option 2: Screen/Tmux Session (For Testing/Development)**

Run the orchestrator in a detached terminal session:

#### Using Screen:
```bash
# Start new screen session
screen -S synexs-orchestrator

# Run orchestrator
cd /root/synexs
/root/synexs/synexs_env/bin/python3 synexs_core_orchestrator.py

# Detach: Press Ctrl+A then D

# Reattach later
screen -r synexs-orchestrator

# List all screens
screen -ls
```

#### Using Tmux:
```bash
# Start new tmux session
tmux new -s synexs-orchestrator

# Run orchestrator
cd /root/synexs
/root/synexs/synexs_env/bin/python3 synexs_core_orchestrator.py

# Detach: Press Ctrl+B then D

# Reattach later
tmux attach -t synexs-orchestrator

# List all sessions
tmux ls
```

---

### **Option 3: Docker Container (For Portability)**

Run the orchestrator in a Docker container:

```bash
# Build container
docker build -t synexs-orchestrator -f - . << 'EOF'
FROM python:3.8-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["/app/synexs_env/bin/python3", "synexs_core_orchestrator.py"]
EOF

# Run container
docker run -d \
  --name synexs-orchestrator \
  --restart unless-stopped \
  -v /root/synexs:/app \
  synexs-orchestrator

# View logs
docker logs -f synexs-orchestrator

# Stop/start
docker stop synexs-orchestrator
docker start synexs-orchestrator
```

---

## How the Orchestrator Works

### Execution Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Orchestrator Cycle                      â”‚
â”‚                   (Every 60 seconds)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: GENERATION                                      â”‚
â”‚ â€¢ cell_001.py - Generate initial sequences               â”‚
â”‚ â€¢ (cell_002.py runs independently as continuous service) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2: PROCESSING                                      â”‚
â”‚ â€¢ cell_004.py - Process raw sequences                    â”‚
â”‚ â€¢ cell_010_parser.py - Parse and refine                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3: CLASSIFICATION                                  â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ ğŸ¤– PRE-HOOK: AI Decision Generation                â”‚   â”‚
â”‚ â”‚ â€¢ Load sequences from datasets/refined/            â”‚   â”‚
â”‚ â”‚ â€¢ Generate AI predictions with confidence scores   â”‚   â”‚
â”‚ â”‚ â€¢ Save to datasets/ai_decisions/latest_decisions   â”‚   â”‚
â”‚ â”‚ â€¢ Log decisions to ai_decisions_log.jsonl          â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                           â”‚
â”‚ â€¢ cell_006.py - Classify sequences using trained model   â”‚
â”‚   - In shadow mode: Uses rule-based logic              â”‚
â”‚   - AI decisions run in parallel for comparison        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 4: EVOLUTION                                       â”‚
â”‚ â€¢ cell_014_mutator.py - Mutate sequences                 â”‚
â”‚ â€¢ cell_015_replicator.py - Replicate successful patternsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 5: FEEDBACK                                        â”‚
â”‚ â€¢ cell_016_feedback_loop.py - Analyze results            â”‚
â”‚                                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ ğŸ“Š POST-HOOK: Training Data Collection            â”‚   â”‚
â”‚ â”‚ â€¢ Load decisions from datasets/decisions/          â”‚   â”‚
â”‚ â”‚ â€¢ Collect training samples (10 per cycle)          â”‚   â”‚
â”‚ â”‚ â€¢ Buffer samples for batch training                â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”„ Retraining Check (Every 100 Cycles)                   â”‚
â”‚ â€¢ Flush training buffer to disk                          â”‚
â”‚ â€¢ Run cell_016_model_trainer.py                          â”‚
â”‚ â€¢ Reload model with new weights                          â”‚
â”‚ â€¢ Continue with improved predictions                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                    Sleep 60s â†’ Repeat
```

### Shadow Mode Operation

**Current State: Shadow Mode Enabled**

- AI predictions run in parallel with normal operations
- System continues using rule-based decisions (safe)
- AI decisions are logged for comparison: `ai_decisions_log.jsonl`
- Metrics tracked: confidence scores, fallback rate, source distribution
- No impact on system behavior (testing phase)

**What Gets Logged:**
```json
{
  "sequence": "SCAN ATTACK REPLICATE",
  "action": "DEFEND",
  "confidence": 0.187,
  "source": "fallback",
  "timestamp": "2025-12-15T00:49:38.123456"
}
```

**Metrics Example:**
```
ğŸ“Š AI Metrics: {'fallback': 149, 'ai': 1}, Avg Confidence: 0.351
```
- 149/150 used fallback (low confidence < 0.6)
- 1/150 used pure AI (confidence â‰¥ 0.6)
- Average confidence: 0.351 (model needs training)

---

## Configuration

### AI Config File: `ai_config.json`

```json
{
  "version": "3.0",
  "protocol": "v3",

  "ai_mode": {
    "enabled": true,
    "shadow_mode": true,              // â† AI runs but doesn't affect decisions
    "fallback_enabled": true,          // â† Use rules if confidence < threshold
    "confidence_threshold": 0.6,       // â† Minimum confidence for AI decisions
    "gradual_rollout_percentage": 0    // â† 0% = shadow only, 100% = full AI
  },

  "training": {
    "auto_retrain": true,
    "retrain_every_n_cycles": 100,     // â† Retrain every 100 cycles
    "min_samples_for_retrain": 500,
    "batch_size": 32,
    "epochs": 10,
    "learning_rate": 0.001
  },

  "monitoring": {
    "log_decisions": true,
    "log_training_samples": true,
    "metrics_interval": 10
  },

  "actions": {
    "v3_actions": [
      "SCAN", "ATTACK", "REPLICATE", "MUTATE", "EVADE",
      "LEARN", "REPORT", "DEFEND", "REFINE", "FLAG",
      // ... 32 total V3 actions
    ]
  }
}
```

---

## Transitioning to Full AI Mode

### Gradual Rollout Path

#### **Phase 1: Shadow Mode (Current - Weeks 1-2)**
```json
{
  "ai_mode": {
    "shadow_mode": true,
    "gradual_rollout_percentage": 0
  }
}
```
- AI runs in background
- Monitor metrics: `tail -f ai_decisions_log.jsonl`
- Compare AI vs rule-based accuracy
- Wait for average confidence to improve

#### **Phase 2: 10% Rollout (Week 3)**
```json
{
  "ai_mode": {
    "shadow_mode": false,
    "gradual_rollout_percentage": 10
  }
}
```
- 10% of decisions use AI
- 90% use rule-based logic
- Monitor for errors/anomalies
- Adjust confidence threshold if needed

#### **Phase 3: 25% Rollout (Week 4)**
```json
{
  "ai_mode": {
    "shadow_mode": false,
    "gradual_rollout_percentage": 25
  }
}
```
- Increase to 25%
- Continue monitoring
- Check training buffer growth

#### **Phase 4: 50% Rollout (Week 5)**
```json
{
  "ai_mode": {
    "shadow_mode": false,
    "gradual_rollout_percentage": 50
  }
}
```
- Half AI, half rules
- Compare performance metrics
- Ensure retraining is working

#### **Phase 5: Full AI (Week 6+)**
```json
{
  "ai_mode": {
    "shadow_mode": false,
    "gradual_rollout_percentage": 100,
    "confidence_threshold": 0.5
  }
}
```
- 100% AI decisions (with fallback if confidence < 0.5)
- Continuous learning active
- Auto-retraining every 100 cycles

---

## Monitoring & Maintenance

### Key Log Files

1. **Orchestrator Log:** `/root/synexs/synexs_core.log`
   - Cycle execution status
   - Cell success/failure
   - AI metrics
   - Retraining events

2. **AI Decision Log:** `/root/synexs/ai_decisions_log.jsonl`
   - Every AI prediction
   - Confidence scores
   - Fallback decisions
   - Timestamps

3. **System Journal:** `journalctl -u synexs-orchestrator`
   - Service status
   - Start/stop events
   - Crash reports

### Monitoring Commands

```bash
# Watch orchestrator in real-time
tail -f /root/synexs/synexs_core.log

# Count AI decisions by source
cat ai_decisions_log.jsonl | jq -r '.source' | sort | uniq -c

# Calculate average confidence
cat ai_decisions_log.jsonl | jq -r '.confidence' | awk '{sum+=$1; count++} END {print sum/count}'

# Check training buffer size
grep "Training buffer" synexs_core.log | tail -1

# View last retraining event
grep "retraining" synexs_core.log | tail -5

# Check cycle success rate
grep "Cycle #" synexs_core.log | tail -20
```

### Health Checks

The orchestrator performs health checks every 10 cycles:
- CPU usage
- Memory usage
- Disk usage

Check health in logs:
```bash
grep "Health:" synexs_core.log | tail -10
```

---

## Troubleshooting

### Issue: Orchestrator won't start
```bash
# Check Python environment
/root/synexs/synexs_env/bin/python3 --version

# Check dependencies
/root/synexs/synexs_env/bin/pip list | grep torch

# Run manually to see errors
cd /root/synexs
/root/synexs/synexs_env/bin/python3 synexs_core_orchestrator.py
```

### Issue: Cells failing
```bash
# Check which cells failed
grep "âŒ" synexs_core.log | tail -20

# Run individual cell manually
cd /root/synexs
/root/synexs/synexs_env/bin/python3 cells/cell_006.py
```

### Issue: Low AI confidence
This is normal initially. The model improves through:
- Continuous training data collection
- Auto-retraining every 100 cycles
- More diverse sequences

Check improvement:
```bash
# Watch confidence trend
grep "Avg Confidence" synexs_core.log
```

### Issue: AI not making decisions
```bash
# Verify AI engine loaded
grep "AI Engine initialized" synexs_core.log

# Check shadow mode status
cat ai_config.json | jq '.ai_mode.shadow_mode'

# Verify decisions file created
ls -lh datasets/ai_decisions/latest_decisions.json
```

---

## Performance Metrics

### Current Baseline (After 1 Cycle)
- **Cycles completed:** 1
- **AI decisions generated:** 150
- **Average confidence:** 0.351
- **Fallback rate:** 99.3% (149/150)
- **AI usage:** 0.7% (1/150)
- **Training samples collected:** 10

### Expected After 100 Cycles
- **First retraining triggered**
- **Confidence should improve:** 0.35 â†’ 0.45+
- **Fallback rate should decrease:** 99% â†’ 70%
- **Training samples:** 1,000+

### Target Production Metrics
- **Average confidence:** > 0.70
- **Fallback rate:** < 20%
- **AI usage:** > 80%
- **Retraining frequency:** Every 100 cycles
- **Model accuracy:** > 85%

---

## Next Steps

### Immediate (This Week)
1. âœ… Deploy orchestrator as systemd service
2. âœ… Monitor shadow mode for 100 cycles
3. âœ… Let first auto-retraining happen (cycle 100)
4. âœ… Analyze confidence improvement

### Short-term (Weeks 2-4)
5. Begin gradual rollout: 10% â†’ 25% â†’ 50%
6. Compare AI vs rule-based accuracy
7. Adjust confidence threshold based on data
8. Fine-tune retraining frequency

### Long-term (Month 2+)
9. Achieve 100% AI mode
10. Optimize retraining schedule
11. Implement advanced metrics dashboard
12. Scale to multiple agents/instances

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Synexs Ecosystem                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  cell_002.py â”‚    â”‚ DNA Collectorâ”‚   â”‚  Honeypot    â”‚   â”‚
â”‚  â”‚ (Generator)  â”‚â”€â”€â”€â–¶â”‚  (30min cron)â”‚â—€â”€â”€â”‚  Listener    â”‚   â”‚
â”‚  â”‚ Standalone   â”‚    â”‚              â”‚   â”‚              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                               â”‚
â”‚                              â–¼                               â”‚
â”‚                    datasets/generated/                       â”‚
â”‚                              â”‚                               â”‚
â”‚                              â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚     Synexs Core Orchestrator (This Service)         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚        AI Decision Engine (Shadow Mode)      â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Confidence-based predictions              â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Fallback to rules if confidence < 0.6     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Training data collection buffer           â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Auto-retrain every 100 cycles             â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  Executes in order (every 60s):                      â”‚   â”‚
â”‚  â”‚  1. Generation   â†’ cell_001.py                       â”‚   â”‚
â”‚  â”‚  2. Processing   â†’ cell_004.py, cell_010_parser.py   â”‚   â”‚
â”‚  â”‚  3. ğŸ¤– AI Pre-hook â†’ Generate AI decisions            â”‚   â”‚
â”‚  â”‚  4. Classification â†’ cell_006.py                     â”‚   â”‚
â”‚  â”‚  5. Evolution    â†’ cell_014, cell_015                â”‚   â”‚
â”‚  â”‚  6. Feedback     â†’ cell_016_feedback_loop.py         â”‚   â”‚
â”‚  â”‚  7. ğŸ“Š AI Post-hook â†’ Collect training samples       â”‚   â”‚
â”‚  â”‚  8. ğŸ”„ Retraining check (every 100 cycles)            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                               â”‚
â”‚                              â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Data Flow                               â”‚   â”‚
â”‚  â”‚  datasets/refined/ â†’ datasets/decisions/             â”‚   â”‚
â”‚  â”‚  datasets/mutated/ â†’ datasets/replicated/            â”‚   â”‚
â”‚  â”‚  datasets/core_training/ (training samples)          â”‚   â”‚
â”‚  â”‚  datasets/ai_decisions/ (AI predictions)             â”‚   â”‚
â”‚  â”‚  ai_decisions_log.jsonl (audit trail)                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Summary

**Recommended Deployment:**
- Use **systemd service** for production (auto-start, auto-restart)
- Use **screen/tmux** for development/testing
- Run in **shadow mode** initially to validate AI performance
- Gradually transition to full AI mode over 6 weeks
- Monitor logs and metrics continuously
- Let auto-retraining improve the model over time

The orchestrator is now a **self-improving system** that:
1. Runs all cells in coordinated phases
2. Generates AI predictions in parallel (shadow mode)
3. Collects training data automatically
4. Retrains the model every 100 cycles
5. Continuously improves decision quality
6. Saves 78.6% bandwidth with V3 protocol

**Start it now:**
```bash
sudo systemctl start synexs-orchestrator
sudo journalctl -u synexs-orchestrator -f
```
